{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMbDUKf5S6vyI9Hwhdkr1T7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Feature Engineering Overview\n","\n","Build new features to improve our model’s predictive power. Focus on rolling returns, volatility, momentum, and market regime signals.\n","\n","- Calculate rolling returns and volatility\n","- Add sector and ETF-relative features\n","- Build momentum and reversal indicators\n","- Merge in market cap, ETF, and VIX signals\n","- Prepare final wide dataset for model input\n"],"metadata":{"id":"PGT2fAu87Uep"}},{"cell_type":"markdown","source":["## 1. Load Cleaned OHLCV and SPY Data\n","\n","We start from our single cleaned stock file and merge SPY daily closes by date. This ensures every row is aligned to the actual market calendar and can reference SPY for market regime and relative features.\n"],"metadata":{"id":"1U4CUjq37WvX"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IZjD2W1i4M0_","executionInfo":{"status":"ok","timestamp":1752098011876,"user_tz":420,"elapsed":4767,"user":{"displayName":"Aryaz Zomorodi","userId":"04002852148298941149"}},"outputId":"361dc839-a0fc-49d2-b949-3489d28a5d9e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Merged SPY close onto stocks. Example rows:\n","        date final_ticker     open     high      low    close  px_volume  \\\n","0 2005-04-15           AA  66.1789  67.4331  65.2831  65.6190  3797001.0   \n","1 2005-04-18           AA  65.6414  67.0747  65.3951  66.2685  2941698.0   \n","2 2005-04-19           AA  66.1341  67.0747  65.0815  65.8206  3017338.0   \n","3 2005-04-20           AA  65.6638  65.7758  64.3313  64.7232  2400296.0   \n","4 2005-04-21           AA  65.1263  66.2909  64.3201  66.1789  2780416.0   \n","\n","   close_spy  \n","0     114.15  \n","1     114.50  \n","2     115.41  \n","3     113.80  \n","4     116.01  \n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","df = pd.read_csv('ohlcv_master_clean.csv', parse_dates=['date'])\n","spy = pd.read_csv('spy_ohlcv.csv', parse_dates=['date'])\n","spy = spy.rename(columns={\n","    'px_open': 'spy_open',\n","    'px_high': 'spy_high',\n","    'px_low': 'spy_low',\n","    'px_last': 'close_spy',\n","    'px_volume': 'spy_volume'\n","})\n","\n","df = df.merge(spy[['date','close_spy']], on='date', how='left')\n","print(\"Merged SPY close onto stocks. Example rows:\")\n","print(df.head())\n"]},{"cell_type":"markdown","source":["## 2. Merge in VIX Data\n","\n","We add VIX (market volatility index) by date. This gives us a signal for market risk appetite and stress, useful for regime features and model context.\n"],"metadata":{"id":"y2sHThHA7dKn"}},{"cell_type":"code","source":["import yfinance as yf\n","\n","# Grab VIX from Yahoo. Sometimes the columns change, so we check what’s actually there.\n","vix = yf.download('^VIX', start=df['date'].min(), end=df['date'].max())\n","\n","# If there’s a multi-level header, flatten it out.\n","if isinstance(vix.columns, pd.MultiIndex):\n","    vix.columns = ['_'.join(col).strip() for col in vix.columns.values]\n","\n","# Put the index back to a normal column so it's easy to merge later.\n","vix = vix.reset_index()\n","\n","# Quick sanity check—print the columns so we can see what we got from Yahoo.\n","print(\"VIX columns after reset_index:\", vix.columns.tolist())\n","\n","# Find whatever the 'close' column is actually named and rename it for merging.\n","close_col = None\n","for col in vix.columns:\n","    if col.lower() == 'close':\n","        close_col = col\n","        break\n","    if 'close' in col.lower():\n","        close_col = col\n","if not close_col:\n","    raise ValueError(\"No close column found in VIX data. Columns: \" + str(vix.columns))\n","\n","# Now rename to 'vix_close' so the merge is simple and clear.\n","vix = vix.rename(columns={'Date':'date', close_col:'vix_close'})\n","vix['date'] = pd.to_datetime(vix['date'])\n","df['date'] = pd.to_datetime(df['date'])\n","\n","# Merge VIX onto our main data by date—this always works, even if the column names change again.\n","df = df.merge(vix[['date', 'vix_close']], on='date', how='left')\n","\n","# Build a daily VIX return and 10-day rolling VIX volatility—both can be useful for regime filters or as model inputs.\n","df['vix_return_1d'] = df['vix_close'].pct_change(1, fill_method=None)\n","df['vix_vol_10'] = df['vix_close'].rolling(10).std()\n","\n","# Spot check that the columns all landed where we want them.\n","print(df[['date','vix_close','vix_return_1d','vix_vol_10']].head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1DKnk8U77dea","executionInfo":{"status":"ok","timestamp":1752098014684,"user_tz":420,"elapsed":2806,"user":{"displayName":"Aryaz Zomorodi","userId":"04002852148298941149"}},"outputId":"c0b83e22-1688-444d-f461-7ab9635bdf7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2-2196075390.py:4: FutureWarning: YF.download() has changed argument auto_adjust default to True\n","  vix = yf.download('^VIX', start=df['date'].min(), end=df['date'].max())\n","[*********************100%***********************]  1 of 1 completed\n"]},{"output_type":"stream","name":"stdout","text":["VIX columns after reset_index: ['Date', 'Close_^VIX', 'High_^VIX', 'Low_^VIX', 'Open_^VIX', 'Volume_^VIX']\n","        date  vix_close  vix_return_1d  vix_vol_10\n","0 2005-04-15  17.740000            NaN         NaN\n","1 2005-04-18  16.559999      -0.066516         NaN\n","2 2005-04-19  14.960000      -0.096618         NaN\n","3 2005-04-20  16.920000       0.131016         NaN\n","4 2005-04-21  14.410000      -0.148345         NaN\n"]}]},{"cell_type":"markdown","source":["## 3. Merge in Sector ETF Data\n","\n","We join daily closing prices and returns from each GICS sector ETF (e.g., XLK, XLF, etc.). This lets us model both absolute and relative sector moves as potential predictors.\n"],"metadata":{"id":"idPCpqWo7gWD"}},{"cell_type":"code","source":["import yfinance as yf\n","import warnings\n","\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","\n","sector_etfs = ['XLK', 'XLF', 'XLV', 'XLY', 'XLC', 'XLI', 'XLE', 'XLRE', 'XLP', 'XLB', 'XLU']\n","\n","for etf in sector_etfs:\n","    # Pull daily data for the ETF, flatten any multi-level headers just in case\n","    etf_data = yf.download(etf, start=df['date'].min(), end=df['date'].max())\n","    if isinstance(etf_data.columns, pd.MultiIndex):\n","        etf_data.columns = ['_'.join(col).strip() for col in etf_data.columns.values]\n","    etf_data = etf_data.reset_index()\n","    print(f\"{etf} columns after reset_index:\", etf_data.columns.tolist())\n","\n","    # Figure out what the close column is actually called\n","    close_col = None\n","    for col in etf_data.columns:\n","        if 'close' in col.lower():\n","            close_col = col\n","            break\n","    if not close_col:\n","        raise ValueError(f\"No close column found for {etf}. Columns: {etf_data.columns}\")\n","\n","    # Rename only the date column so it's consistent for the merge\n","    if 'Date' in etf_data.columns:\n","        etf_data = etf_data.rename(columns={'Date': 'date'})\n","    etf_data['date'] = pd.to_datetime(etf_data['date'])\n","    df['date'] = pd.to_datetime(df['date'])\n","\n","    # Merge the actual close column into our DataFrame under its native name\n","    df = df.merge(etf_data[['date', close_col]], on='date', how='left')\n","\n","    # Create a return column based on that close column\n","    ret_col = f\"{etf}_ret_5d\"\n","    df[ret_col] = df[close_col].pct_change(5, fill_method=None)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kI7sfFRj7ga-","executionInfo":{"status":"ok","timestamp":1752098027433,"user_tz":420,"elapsed":12740,"user":{"displayName":"Aryaz Zomorodi","userId":"04002852148298941149"}},"outputId":"f44a118b-48f7-4482-a7f0-e51aab07791b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r[*********************100%***********************]  1 of 1 completed\n"]},{"output_type":"stream","name":"stdout","text":["XLK columns after reset_index: ['Date', 'Close_XLK', 'High_XLK', 'Low_XLK', 'Open_XLK', 'Volume_XLK']\n"]},{"output_type":"stream","name":"stderr","text":["\r[*********************100%***********************]  1 of 1 completed\n"]},{"output_type":"stream","name":"stdout","text":["XLF columns after reset_index: ['Date', 'Close_XLF', 'High_XLF', 'Low_XLF', 'Open_XLF', 'Volume_XLF']\n"]},{"output_type":"stream","name":"stderr","text":["\r[*********************100%***********************]  1 of 1 completed\n"]},{"output_type":"stream","name":"stdout","text":["XLV columns after reset_index: ['Date', 'Close_XLV', 'High_XLV', 'Low_XLV', 'Open_XLV', 'Volume_XLV']\n"]},{"output_type":"stream","name":"stderr","text":["\r[*********************100%***********************]  1 of 1 completed\n"]},{"output_type":"stream","name":"stdout","text":["XLY columns after reset_index: ['Date', 'Close_XLY', 'High_XLY', 'Low_XLY', 'Open_XLY', 'Volume_XLY']\n"]},{"output_type":"stream","name":"stderr","text":["\r[*********************100%***********************]  1 of 1 completed\n"]},{"output_type":"stream","name":"stdout","text":["XLC columns after reset_index: ['Date', 'Close_XLC', 'High_XLC', 'Low_XLC', 'Open_XLC', 'Volume_XLC']\n"]},{"output_type":"stream","name":"stderr","text":["\r[*********************100%***********************]  1 of 1 completed\n"]},{"output_type":"stream","name":"stdout","text":["XLI columns after reset_index: ['Date', 'Close_XLI', 'High_XLI', 'Low_XLI', 'Open_XLI', 'Volume_XLI']\n"]},{"output_type":"stream","name":"stderr","text":["\r[*********************100%***********************]  1 of 1 completed\n"]},{"output_type":"stream","name":"stdout","text":["XLE columns after reset_index: ['Date', 'Close_XLE', 'High_XLE', 'Low_XLE', 'Open_XLE', 'Volume_XLE']\n"]},{"output_type":"stream","name":"stderr","text":["\r[*********************100%***********************]  1 of 1 completed\n"]},{"output_type":"stream","name":"stdout","text":["XLRE columns after reset_index: ['Date', 'Close_XLRE', 'High_XLRE', 'Low_XLRE', 'Open_XLRE', 'Volume_XLRE']\n"]},{"output_type":"stream","name":"stderr","text":["\r[*********************100%***********************]  1 of 1 completed\n"]},{"output_type":"stream","name":"stdout","text":["XLP columns after reset_index: ['Date', 'Close_XLP', 'High_XLP', 'Low_XLP', 'Open_XLP', 'Volume_XLP']\n"]},{"output_type":"stream","name":"stderr","text":["\r[*********************100%***********************]  1 of 1 completed\n"]},{"output_type":"stream","name":"stdout","text":["XLB columns after reset_index: ['Date', 'Close_XLB', 'High_XLB', 'Low_XLB', 'Open_XLB', 'Volume_XLB']\n"]},{"output_type":"stream","name":"stderr","text":["\r[*********************100%***********************]  1 of 1 completed\n"]},{"output_type":"stream","name":"stdout","text":["XLU columns after reset_index: ['Date', 'Close_XLU', 'High_XLU', 'Low_XLU', 'Open_XLU', 'Volume_XLU']\n"]}]},{"cell_type":"markdown","source":["## 4a. Feature Engineering for Each Ticker\n","\n","We now engineer all technical indicators, momentum, volatility, and regime signals for each ticker. These are industry-standard predictors used in quant equity models.\n"],"metadata":{"id":"cdOIqKAT7jUZ"}},{"cell_type":"code","source":["frames = []\n","for ticker, group in df.groupby('final_ticker'):\n","    # Always sort by date, so all our rolling windows and shifts are aligned in time\n","    group = group.sort_values('date').reset_index(drop=True)\n","\n","    # 1-day, 5-day, and 21-day returns for each ticker (basic momentum and mean reversion signals)\n","    group['return_1d'] = group['close'].pct_change(1)\n","    group['return_5d'] = group['close'].pct_change(5)\n","    group['return_21d'] = group['close'].pct_change(21)\n","\n","    # 10-day price momentum (used a lot in cross-sectional quant models)\n","    group['momentum_10'] = group['close'] / group['close'].shift(10) - 1\n","\n","    # Simple moving averages for trend direction—SMA 10 and SMA 20 are staples for short- and medium-term bias\n","    group['sma_10'] = group['close'].rolling(10).mean()\n","    group['sma_20'] = group['close'].rolling(20).mean()\n","\n","    # Rolling volatility over 10 and 20 days; useful for regime filters or risk targeting\n","    group['vol_10'] = group['close'].rolling(10).std()\n","    group['vol_20'] = group['close'].rolling(20).std()\n","\n","    # RSI-14: Classic overbought/oversold oscillator (using Wilder's smoothing)\n","    delta = group['close'].diff()\n","    up = delta.clip(lower=0)\n","    down = -delta.clip(upper=0)\n","    gain = up.rolling(14).mean()\n","    loss = down.rolling(14).mean()\n","    rs = gain / loss\n","    group['rsi_14'] = 100 - (100/(1+rs))\n","\n","    # MACD: Trend-following momentum indicator—captures the difference between fast and slow EMAs\n","    group['ema_12'] = group['close'].ewm(span=12, adjust=False).mean()\n","    group['ema_26'] = group['close'].ewm(span=26, adjust=False).mean()\n","    group['macd'] = group['ema_12'] - group['ema_26']\n","    group['macd_signal'] = group['macd'].ewm(span=9, adjust=False).mean()\n","\n","    # Rolling 10-day average volume, and \"volume above average\" as a relative activity signal\n","    group['vol_avg_10'] = group['px_volume'].rolling(10).mean()\n","    group['vol_above_avg'] = (group['px_volume'] - group['vol_avg_10']) / group['vol_avg_10']\n","\n","    # Donchian channels: Highest high and lowest low over the last 20 days—breakout or range signals\n","    group['donchian_high_20'] = group['high'].rolling(20).max()\n","    group['donchian_low_20'] = group['low'].rolling(20).min()\n","\n","    # True range: Captures the actual range of price movement, including gaps\n","    group['true_range'] = group[['high', 'low', 'close']].apply(\n","        lambda row: max(\n","            row['high'] - row['low'],\n","            abs(row['high'] - row['close']),\n","            abs(row['low'] - row['close'])\n","        ), axis=1\n","    )\n","\n","    # Future 5-day return for supervised learning (this is our target)\n","    group['future_return_5d'] = group['close'].shift(-5) / group['close'] - 1\n","\n","    # Excess return over SPY—measures if the ticker is outperforming the broad market over 5 days\n","    group['excess_return_5d'] = group['return_5d'] - group['close_spy'].pct_change(5)\n","\n","    # Rolling beta and correlation vs. SPY for each ticker (measures sensitivity and co-movement with the market)\n","    stock_return = group['close'].pct_change()\n","    spy_return = group['close_spy'].pct_change()\n","    group['beta_60d'] = stock_return.rolling(60).cov(spy_return) / spy_return.rolling(60).var()\n","    group['corr_60d'] = stock_return.rolling(60).corr(spy_return)\n","\n","    frames.append(group)\n","\n","# Concatenate all tickers back into a single DataFrame\n","df_feat = pd.concat(frames, ignore_index=True)\n","print(\"Feature engineering complete. Columns:\", df_feat.columns.tolist())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y33VohwV7jYu","executionInfo":{"status":"ok","timestamp":1752098051047,"user_tz":420,"elapsed":23605,"user":{"displayName":"Aryaz Zomorodi","userId":"04002852148298941149"}},"outputId":"a890a562-d9ae-4b51-ca36-a9d68f3638ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Feature engineering complete. Columns: ['date', 'final_ticker', 'open', 'high', 'low', 'close', 'px_volume', 'close_spy', 'vix_close', 'vix_return_1d', 'vix_vol_10', 'Close_XLK', 'XLK_ret_5d', 'Close_XLF', 'XLF_ret_5d', 'Close_XLV', 'XLV_ret_5d', 'Close_XLY', 'XLY_ret_5d', 'Close_XLC', 'XLC_ret_5d', 'Close_XLI', 'XLI_ret_5d', 'Close_XLE', 'XLE_ret_5d', 'Close_XLRE', 'XLRE_ret_5d', 'Close_XLP', 'XLP_ret_5d', 'Close_XLB', 'XLB_ret_5d', 'Close_XLU', 'XLU_ret_5d', 'return_1d', 'return_5d', 'return_21d', 'momentum_10', 'sma_10', 'sma_20', 'vol_10', 'vol_20', 'rsi_14', 'ema_12', 'ema_26', 'macd', 'macd_signal', 'vol_avg_10', 'vol_above_avg', 'donchian_high_20', 'donchian_low_20', 'true_range', 'future_return_5d', 'excess_return_5d', 'beta_60d', 'corr_60d']\n"]}]},{"cell_type":"markdown","source":["## 4b. Clean Up Duplicate and Messy Columns\n","\n","After merging in VIX and sector ETF data, we’re left with a bunch of duplicate or awkwardly named columns—mostly from how pandas and yfinance handle repeated merges. Before moving forward, we clean these up:\n","\n","- Drop all redundant columns left over from merges (like `*_x`, `*_y`, and `Close_XLK`).\n","- Standardize the naming for all sector ETF close columns (so everything is consistently `XLK_close`, `XLF_close`, etc.).\n","- Double-check the final column list to make sure it’s tidy and ready for modeling.\n","\n","This keeps our dataset organized and ensures our feature selection and modeling steps are using the right data.\n"],"metadata":{"id":"m_-IYUDl_gXU"}},{"cell_type":"code","source":["# First, let's get rid of the duplicate columns left over from all our merges\n","# We'll keep the main vix_close and only one clean ETF close column for each sector\n","drop_cols = [\n","    'vix_close_x', 'vix_close_y',\n","    'XLK_close_x', 'XLK_close_y',\n","]\n","\n","# Any other columns from yfinance that start with 'Close_' (like 'Close_XLK') can go too\n","drop_cols += [col for col in df_feat.columns if col.startswith('Close_')]\n","\n","# Drop everything in our drop list if it actually made it into the DataFrame\n","df_feat = df_feat.drop(columns=[col for col in drop_cols if col in df_feat.columns])\n","\n","# Now, make sure every ETF close column has the same naming style—makes it way easier to work with downstream\n","sector_etfs = ['XLK', 'XLF', 'XLV', 'XLY', 'XLC', 'XLI', 'XLE', 'XLRE', 'XLP', 'XLB', 'XLU']\n","for etf in sector_etfs:\n","    # Sometimes we have a weird mix of cases or suffixes, so find anything that could be the close for this ETF\n","    candidates = [col for col in df_feat.columns if (col.lower().endswith(f'{etf.lower()}_close') or col == f'Close_{etf}')]\n","    if candidates:\n","        df_feat = df_feat.rename(columns={candidates[0]: f'{etf}_close'})\n","\n","# Last check—print out our column names so we can see at a glance that things are tidy\n","print(\"Columns after cleaning:\", df_feat.columns.tolist())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A90MVfpM_glu","executionInfo":{"status":"ok","timestamp":1752098051244,"user_tz":420,"elapsed":204,"user":{"displayName":"Aryaz Zomorodi","userId":"04002852148298941149"}},"outputId":"1035363b-a243-49eb-aa1f-eeb775fb1be1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Columns after cleaning: ['date', 'final_ticker', 'open', 'high', 'low', 'close', 'px_volume', 'close_spy', 'vix_close', 'vix_return_1d', 'vix_vol_10', 'XLK_ret_5d', 'XLF_ret_5d', 'XLV_ret_5d', 'XLY_ret_5d', 'XLC_ret_5d', 'XLI_ret_5d', 'XLE_ret_5d', 'XLRE_ret_5d', 'XLP_ret_5d', 'XLB_ret_5d', 'XLU_ret_5d', 'return_1d', 'return_5d', 'return_21d', 'momentum_10', 'sma_10', 'sma_20', 'vol_10', 'vol_20', 'rsi_14', 'ema_12', 'ema_26', 'macd', 'macd_signal', 'vol_avg_10', 'vol_above_avg', 'donchian_high_20', 'donchian_low_20', 'true_range', 'future_return_5d', 'excess_return_5d', 'beta_60d', 'corr_60d']\n"]}]},{"cell_type":"markdown","source":["## 5. Pull and Merge yfinance Fundamentals\n","\n","For each ticker, we grab core fundamental ratios and metadata. For SPY (ETF), all these values are set as missing since yfinance does not provide fundamental data for index ETFs.\n"],"metadata":{"id":"4wRS0Y-i7q_I"}},{"cell_type":"code","source":["import yfinance as yf\n","\n","# 'sector_etfs' is already defined above, so we just use it here\n","tickers = sorted([\n","    t for t in df_feat['final_ticker'].unique()\n","    if t.isalpha() and len(t) <= 5 and t not in ['SPY'] + sector_etfs\n","])\n","\n","all_info = []\n","for tkr in tickers:\n","    try:\n","        # Pull info from yfinance—ignore if there's a failure\n","        yf_ticker = yf.Ticker(tkr)\n","        info = yf_ticker.info\n","        all_info.append({\n","            \"final_ticker\": tkr,\n","            \"market_cap\": info.get(\"marketCap\"),\n","            \"trailing_pe\": info.get(\"trailingPE\"),\n","            \"forward_pe\": info.get(\"forwardPE\"),\n","            \"price_to_book\": info.get(\"priceToBook\"),\n","            \"dividend_yield\": info.get(\"dividendYield\"),\n","            \"beta\": info.get(\"beta\"),\n","            \"sector\": info.get(\"sector\"),\n","            \"industry\": info.get(\"industry\"),\n","        })\n","    except Exception as e:\n","        print(f\"Couldn’t pull fundamentals for {tkr}: {e}\")\n","\n","df_fund = pd.DataFrame(all_info)\n","print(\"Pulled fundamentals for\", len(df_fund), \"tickers\")\n","\n","# Merge on ticker symbol\n","df_feat = df_feat.merge(df_fund, on='final_ticker', how='left')\n","\n","# Set fundamental columns to NaN for SPY and all sector ETFs (these aren't real companies)\n","fundamental_cols = [\n","    \"market_cap\", \"trailing_pe\", \"forward_pe\", \"price_to_book\", \"dividend_yield\", \"beta\"\n","]\n","index_like = ['SPY'] + sector_etfs\n","for col in fundamental_cols:\n","    if col in df_feat.columns:\n","        df_feat.loc[df_feat['final_ticker'].isin(index_like), col] = np.nan\n","\n","print(\"After merging in the fundamentals, here are our columns:\", df_feat.columns.tolist())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8YQZWlz67rEt","executionInfo":{"status":"ok","timestamp":1752098104710,"user_tz":420,"elapsed":53468,"user":{"displayName":"Aryaz Zomorodi","userId":"04002852148298941149"}},"outputId":"fa6ce2eb-1ff6-479d-88e8-aee50d86064c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:yfinance:HTTP Error 404: \n","ERROR:yfinance:HTTP Error 404: \n"]},{"output_type":"stream","name":"stdout","text":["Pulled fundamentals for 162 tickers\n","After merging in the fundamentals, here are our columns: ['date', 'final_ticker', 'open', 'high', 'low', 'close', 'px_volume', 'close_spy', 'vix_close', 'vix_return_1d', 'vix_vol_10', 'XLK_ret_5d', 'XLF_ret_5d', 'XLV_ret_5d', 'XLY_ret_5d', 'XLC_ret_5d', 'XLI_ret_5d', 'XLE_ret_5d', 'XLRE_ret_5d', 'XLP_ret_5d', 'XLB_ret_5d', 'XLU_ret_5d', 'return_1d', 'return_5d', 'return_21d', 'momentum_10', 'sma_10', 'sma_20', 'vol_10', 'vol_20', 'rsi_14', 'ema_12', 'ema_26', 'macd', 'macd_signal', 'vol_avg_10', 'vol_above_avg', 'donchian_high_20', 'donchian_low_20', 'true_range', 'future_return_5d', 'excess_return_5d', 'beta_60d', 'corr_60d', 'market_cap', 'trailing_pe', 'forward_pe', 'price_to_book', 'dividend_yield', 'beta', 'sector', 'industry']\n"]}]},{"cell_type":"markdown","source":["## 6a. Drop Rows Missing Key Features or Target\n","\n","Because some features like rolling statistics and fundamentals require historical data, certain rows will have missing values (NaNs).\n","\n","To keep our modeling clean and reliable, we remove any rows that lack critical input features or the target variable. This step ensures the model only trains and evaluates on complete cases without data gaps.\n"],"metadata":{"id":"eUay8MNC7uxN"}},{"cell_type":"code","source":["# Rolling windows and missing fundamentals mean some rows are going to have NaNs\n","# We'll drop anything missing a key input or our target, so the model's always working with clean data\n","\n","feature_cols = [\n","    'return_1d','return_5d','return_21d','momentum_10','sma_10','sma_20','vol_10','vol_20','rsi_14',\n","    'macd','macd_signal','vol_avg_10','vol_above_avg','donchian_high_20','donchian_low_20','true_range',\n","    'excess_return_5d','beta_60d','corr_60d',\n","    'vix_close','vix_return_1d','vix_vol_10'\n","]\n","\n","# Add sector ETF close and return features\n","feature_cols += [\n","    c for c in df_feat.columns\n","    if any(c.startswith(etf) and (c.endswith('_close') or c.endswith('_ret_5d')) for etf in sector_etfs)\n","]\n","\n","# Add any fundamentals that made it through\n","feature_cols += [c for c in fundamental_cols if c in df_feat.columns]\n","\n","# Drop any rows missing one of our inputs or the target\n","df_feat = df_feat.dropna(subset=feature_cols + ['future_return_5d'])\n","print(\"Shape after dropping NaNs:\", df_feat.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Day6T1_7u5h","executionInfo":{"status":"ok","timestamp":1752098104934,"user_tz":420,"elapsed":226,"user":{"displayName":"Aryaz Zomorodi","userId":"04002852148298941149"}},"outputId":"3c0a9a17-0c4a-4808-9eea-f5cb9cab19fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape after dropping NaNs: (202771, 52)\n"]}]},{"cell_type":"markdown","source":["## 6b. Save Final Engineered Dataset with Fundamentals\n","\n","At this point, all feature engineering, merging of market data, sector ETFs, VIX, and fundamental metrics is complete.\n","\n","Saving this comprehensive dataset to a CSV file ensures a stable, reproducible input for future modeling steps. It prevents the need to rerun costly data preparation and allows us to load consistent data for model training, testing, and analysis.\n"],"metadata":{"id":"1QglyDnPJb-F"}},{"cell_type":"code","source":["# Save the complete feature set including fundamentals for future modeling runs\n","df_feat.to_csv('engine_final_allfeatures_wfund.csv', index=False)\n","print(\"Saved full feature set with fundamentals to 'engine_final_allfeatures_wfund.csv'\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RGYvB7KZJcD8","executionInfo":{"status":"ok","timestamp":1752098141901,"user_tz":420,"elapsed":36970,"user":{"displayName":"Aryaz Zomorodi","userId":"04002852148298941149"}},"outputId":"1df3d854-e3c2-4053-9c6c-667461990a66"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved full feature set with fundamentals to 'engine_final_allfeatures_wfund.csv'\n"]}]},{"cell_type":"markdown","source":["## 7. XGBoost Feature Selection\n","\n","To identify which features truly impact returns, we use XGBoost to rank them by importance. This method handles tabular data well and runs efficiently, helping us focus on the most predictive signals.\n","\n","We train the model on individual stocks only (excluding SPY and all sector ETFs)to avoid bias. Any remaining missing values are filled with medians before training. The result is a clear ranking of top features driving the model’s performance.\n"],"metadata":{"id":"C527nO9q7yIM"}},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","\n","# Define all tickers to exclude from training (SPY and sector ETFs)\n","excluded_tickers = ['SPY', 'XLK', 'XLF', 'XLV', 'XLY', 'XLC', 'XLI', 'XLE', 'XLRE', 'XLP', 'XLB', 'XLU']\n","\n","# Filter to keep only real stocks for training\n","train_df = df_feat[~df_feat['final_ticker'].isin(excluded_tickers)].copy()\n","\n","# Keep only features that actually exist in the DataFrame\n","feature_cols_final = [c for c in feature_cols if c in train_df.columns]\n","X = train_df[feature_cols_final]\n","y = train_df['future_return_5d']\n","\n","# XGBoost can't handle NaNs—fill with medians just in case\n","X = X.fillna(X.median())\n","\n","# Standard train/validation split\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# XGBoost for feature importance—fast, robust, works well with tabular data\n","xgb_model = xgb.XGBRegressor(\n","    n_estimators=200,\n","    max_depth=6,\n","    learning_rate=0.1,\n","    n_jobs=-1,\n","    random_state=42\n",")\n","xgb_model.fit(X_train, y_train)\n","\n","importances = pd.Series(xgb_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n","print(\"Top features by XGBoost:\", importances.head(20))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l9eWQu_77yPh","executionInfo":{"status":"ok","timestamp":1752098158951,"user_tz":420,"elapsed":17051,"user":{"displayName":"Aryaz Zomorodi","userId":"04002852148298941149"}},"outputId":"e13feebb-4a6b-42a7-c608-fcb12f877847"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Top features by XGBoost: vix_close           0.066131\n","XLE_ret_5d          0.061586\n","vix_return_1d       0.055130\n","vix_vol_10          0.051415\n","XLK_ret_5d          0.047226\n","XLP_ret_5d          0.047152\n","XLF_ret_5d          0.041691\n","XLI_ret_5d          0.041051\n","XLY_ret_5d          0.039377\n","XLRE_ret_5d         0.039078\n","XLV_ret_5d          0.038666\n","XLU_ret_5d          0.035815\n","XLB_ret_5d          0.032433\n","XLC_ret_5d          0.032077\n","donchian_low_20     0.028617\n","return_21d          0.027415\n","momentum_10         0.025069\n","beta_60d            0.019131\n","excess_return_5d    0.018977\n","market_cap          0.018668\n","dtype: float32\n"]}]},{"cell_type":"markdown","source":["## 8. Save and Report Top Features\n","\n","We export the top 10 and top 20 features from XGBoost so we can use them for modeling, ablation tests, or documentation. Having these lists saved separately makes it easy to reproduce results, swap features, or compare different model runs.\n"],"metadata":{"id":"DDGvJ5v070II"}},{"cell_type":"code","source":["# Save top 10 and top 20 features to disk for downstream runs or ablation testing\n","top10 = importances.head(10).index.tolist()\n","top20 = importances.head(20).index.tolist()\n","pd.Series(top10).to_csv('top10_features_xgb.csv', index=False)\n","pd.Series(top20).to_csv('top20_features_xgb.csv', index=False)\n","\n","print(\"Top 10 features:\", top10)\n","print(\"Top 20 features:\", top20)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PC565_pU70PE","executionInfo":{"status":"ok","timestamp":1752098158964,"user_tz":420,"elapsed":4,"user":{"displayName":"Aryaz Zomorodi","userId":"04002852148298941149"}},"outputId":"c6816799-ac39-4207-d90d-b33d8d5724af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Top 10 features: ['vix_close', 'XLE_ret_5d', 'vix_return_1d', 'vix_vol_10', 'XLK_ret_5d', 'XLP_ret_5d', 'XLF_ret_5d', 'XLI_ret_5d', 'XLY_ret_5d', 'XLRE_ret_5d']\n","Top 20 features: ['vix_close', 'XLE_ret_5d', 'vix_return_1d', 'vix_vol_10', 'XLK_ret_5d', 'XLP_ret_5d', 'XLF_ret_5d', 'XLI_ret_5d', 'XLY_ret_5d', 'XLRE_ret_5d', 'XLV_ret_5d', 'XLU_ret_5d', 'XLB_ret_5d', 'XLC_ret_5d', 'donchian_low_20', 'return_21d', 'momentum_10', 'beta_60d', 'excess_return_5d', 'market_cap']\n"]}]},{"cell_type":"markdown","source":["## 9. Feature Importance Summary\n","\n","* XGBoost feature selection confirmed that most predictive power for 5-day returns comes from broad market regime indicators and sector-level momentum. VIX levels and returns, plus the 5-day returns of sector ETFs, dominated the rankings. This fits market intuition. Short-term moves are largely driven by overall volatility and sector flows rather than isolated stock factors.\n","\n","* Stock-specific signals like rolling momentum, Donchian channel lows, and rolling beta still contribute meaningfully but play a secondary role. Market cap making the top 20 underscores persistent size-related differences.\n","\n","* In short, macro and sector conditions are the primary drivers for short-term return prediction here. We will move forward using these top features for model building and training.\n"],"metadata":{"id":"H77X9-p37-_M"}}]}